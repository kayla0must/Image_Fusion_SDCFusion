# Scene Degradation-Aware Fusion Network for Robust Infrared and Visible Image Synthesis in Extreme Conditions

This repository provides the official PyTorch implementation of the paper:

> **Scene Degradation-Aware Fusion Network for Robust Infrared and Visible Image Synthesis in Extreme Conditions**  
> *Submitted to The* *** Visual Computer***
> ðŸ“„ [Project Page](https://github.com/kayla0must/Image-fusion)


The method consists of three major components:

1. **Scene Discriminator**: Uses a CLIP-based vision-language model to classify degradation types.
2. **Degradation Correction Units**: Integrates two lightweight modules:
   - **BANet** for brightness adjustment
   - **DFNet** for dehazing
3. **Fusion Backbone**: A multi-stage feature extraction and reconstruction network that merges corrected visible and infrared features.

SDCFuse is trained in **three stages** to progressively enhance the fusion quality with degradation-aware correction.


Repository Structure

```bash
â”œâ”€â”€ Dataloader/            # Dataset loading and preprocessing
â”œâ”€â”€ Model/                # Core model architecture: SDCFuse, BANet, DFNet
â”œâ”€â”€ Train.py              # Fusion training script (Stage 2 & 3)
â”œâ”€â”€ Train_CLS.py          # Scene classifier training script (Stage 1)
â”œâ”€â”€ README.md             # This documentation
